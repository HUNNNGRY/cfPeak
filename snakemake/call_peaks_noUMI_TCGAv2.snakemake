shell.prefix('set -x;')
# include: 'common.snakemake'
include: 'peak_common.snakemake'


# def get_all_inputs(wildcards):
#     available_inputs = dict(
#         ## star index
#         # Genome=expand(genome_dir+'/index/star/{rna_type}/Genome', rna_type=rna_types),
#         # SA=expand(genome_dir+'/index/star/{rna_type}/SA', rna_type=rna_types),

#         # ## bowtie2 index
#         # bt2_1=expand(genome_dir+'/index/bowtie2/{rna_type}.1.bt2', rna_type=rna_types),
#         # bt2rev_1=expand(genome_dir+'/index/bowtie2/{rna_type}.rev.1.bt2', rna_type=rna_types),

#         # bam=expand(output_dir+"/tbam/{sample_id}/bam/{rna_type}.bam",
#         #     sample_id=sample_ids, rna_type=rna_types),
#         # bam_dedup=expand("{output_dir}/tbam/{sample_id}/{bam_dedup_dir}/{rna_type}.bam",
#         #     output_dir=output_dir, sample_id=sample_ids, bam_dedup_dir=bam_dedup_dir, rna_type=rna_types),
#         # bam_dedup_merge_bam=expand("{output_dir}/tbam/{sample_id}/{bam_dedup_dir}/{rna_type}.bam",
#         #     output_dir=output_dir, sample_id=sample_ids, bam_dedup_dir=bam_dedup_dir, rna_type=['merge19_sort','merge11RNA_sort']), # merge11RNA_sort_primary
#         realigned_reverted_bam=expand("{output_dir}/tbam/{sample_id}/{bam_dedup_dir}-EM/{rna_type}/merged.sorted.bam",
#             output_dir=output_dir, sample_id=sample_ids, bam_dedup_dir=bam_dedup_dir, rna_type=['merge19_sort']), #  'merge11RNA_sort',
#         # realigned_reverted_bam2=expand("{output_dir}/tbam/{sample_id}/{bam_dedup_dir}-EM/{rna_type}/{bam_type}",
#         #     output_dir=output_dir, sample_id=sample_ids, bam_dedup_dir=bam_dedup_dir, rna_type=['merge11RNA_sort'],bam_type=['unique.sorted.bam','unique.sorted.revertFullLengthReads.sorted.bam','allrealigned.sorted.bam'] ),

#         # bam_dedup2=expand("{output_dir}/tbam/{sample_id}/{bam_dedup_dir}/{rna_type}.bam",
#         #     output_dir=output_dir, sample_id=sample_ids, bam_dedup_dir=bam_dedup_dir, rna_type=['repeats_for','repeats_rev']),

#         # # #bw
#         # tbw_EM= expand(peak_dir+'/tbigwig_RNA_EM/{sample_id}.transcriptome.bigWig',sample_id=sample_ids),
#         # tbw_primary= expand(peak_dir+'/tbigwig_11RNA_primary/{sample_id}.transcriptome.bigWig',sample_id=sample_ids),


#         # ## merge_reads_by_rnatype=expand(peak_dir+'/tbed_long_RNA/{sample_id}.bed.gz',
#         # ##     sample_id=sample_ids),
#         # ## bed=expand(peak_dir+'/tbed/{sample_id}/{rna_type}.bed.gz',peak_dir=peak_dir,sample_id=sample_ids, rna_type=rna_types),
#         # ## bg=expand(peak_dir+'/tbedgraph_long_RNA/{sample_id}.transcriptome.bedGraph',peak_dir=peak_dir,sample_id=sample_ids),
#     )
#     available_inputs_piranha = dict(
#         # piranha
#         piranha_out=expand(peak_dir+'/piranha_by_sample/b{bin_size}_p{pvalue}/{sample_id}.bed',bin_size=config['bin_size'], pvalue=config['call_peak_pvalue_piranha'], sample_id=sample_ids),
#         peak_piranha=expand(peak_dir+'/piranha/b{bin_size}_p{pvalue}.bed',bin_size=config['bin_size'], pvalue=config['call_peak_pvalue_piranha']),
#         peak_count_matrix_piranha=expand(peak_dir+'/count_matrix/piranha_b{bin_size}_p{pvalue}.txt',bin_size=config['bin_size'], pvalue=config['call_peak_pvalue_piranha'])
#     )
#     available_inputs_clipper = dict(
#         # clipper
#         clipper_out=expand(peak_dir+'/clipper_by_sample/b{bin_size}_p{pvalue}/{sample_id}.bed',bin_size=config['bin_size'], pvalue=config['call_peak_pvalue_clipper'], sample_id=sample_ids),
#         peak_clipper=expand(peak_dir+'/clipper/b{bin_size}_p{pvalue}.bed',bin_size=config['bin_size'], pvalue=config['call_peak_pvalue_clipper']),
#         peak_count_matrix_clipper=expand(peak_dir+'/count_matrix/clipper_b{bin_size}_p{pvalue}.txt',bin_size=config['bin_size'], pvalue=config['call_peak_pvalue_clipper'])
#     )
#     available_inputs_clam = dict(
#         # clam
#         clam_out=expand(peak_dir+'/clam_by_sample/b{bin_size}_p{pvalue}/{sample_id}.bed',bin_size=config['bin_size'], pvalue=config['call_peak_pvalue_clam'], sample_id=sample_ids),
#         peak_clam=expand(peak_dir+'/clam/b{bin_size}_p{pvalue}.bed',bin_size=config['bin_size'], pvalue=config['call_peak_pvalue_clam']),
#         peak_count_matrix_clam=expand(peak_dir+'/count_matrix/clam_b{bin_size}_p{pvalue}.txt',bin_size=config['bin_size'], pvalue=config['call_peak_pvalue_clam'])
#     )
#     available_inputs_cfpeak = dict(
#         # # localmax
#         # localmax_out=expand(peak_dir+'/peaks_localmax_by_sample/b{bin_size}_d{decay}_p{pvalue}/{sample_id}.bed',bin_size=config['bin_size'], decay=config['decay_ratio'], pvalue=config['call_peak_pvalue'], sample_id=sample_ids),
#         # peaks_localmax=expand(peak_dir+'/peaks_localmax/b{bin_size}_d{decay}_p{pvalue}.bed', bin_size=config['bin_size'], decay=config['decay_ratio'], pvalue=config['call_peak_pvalue']),
#         # peak_count_matrix=expand(peak_dir+'/count_matrix/peaks_long_localmax_b{bin_size}_d{decay}_p{pvalue}.txt',peak_dir=peak_dir, bin_size=config['bin_size'], decay=config['decay_ratio'], pvalue=config['call_peak_pvalue']),

#         # ## cfPeak
#         # localmax_out3=expand(peak_dir+'/cfpeak_by_sample/b{bin_size}_d{decay}_p{pvalue}/{sample_id}.bed',bin_size=config['bin_size'],decay=config['decay_ratio'], pvalue=config['call_peak_pvalue_cfpeak'], sample_id=sample_ids),
#         # peak_localmax3=expand(peak_dir+'/cfpeak/b{bin_size}_d{decay}_p{pvalue}.bed', bin_size=config['bin_size'], decay=config['decay_ratio'], pvalue=config['call_peak_pvalue_cfpeak']),
#         # peak_count_matrix3=expand(peak_dir+'/count_matrix/cfpeak_b{bin_size}_d{decay}_p{pvalue}.txt',peak_dir=peak_dir, bin_size=config['bin_size'], decay=config['decay_ratio'], pvalue=config['call_peak_pvalue_cfpeak']),

#         ## cfPeakCNN
#         localmax_out4=expand(peak_dir+'/cfpeakCNN_by_sample/b{bin_size}_d{decay}_p{pvalue}/{sample_id}.bed',bin_size=config['bin_size'],decay=config['decay_ratio'], pvalue=config['call_peak_pvalue_cfpeak'], sample_id=sample_ids),
#         peak_localmax4=expand(peak_dir+'/cfpeakCNN/b{bin_size}_d{decay}_p{pvalue}.bed', bin_size=config['bin_size'], decay=config['decay_ratio'], pvalue=config['call_peak_pvalue_cfpeak']),
#         peak_count_matrix4=expand(peak_dir+'/count_matrix/cfpeakCNN_b{bin_size}_d{decay}_p{pvalue}.txt',peak_dir=peak_dir, bin_size=config['bin_size'], decay=config['decay_ratio'], pvalue=config['call_peak_pvalue_cfpeak'])
#     )

#     inputs = []

#     enabled_inputs = list(available_inputs)
#     for key, l in available_inputs.items():
#         if key in enabled_inputs:
#             inputs += l
    
#     #piranha
#     if config['run_piranha']:
#         enabled_inputs_piranha = list(available_inputs_piranha)
#         for key, l in available_inputs_piranha.items():
#             if key in enabled_inputs_piranha:
#                 inputs += l
#     #clipper
#     if config['run_clipper']:
#         enabled_inputs_clipper = list(available_inputs_clipper)
#         for key, l in available_inputs_clipper.items():
#             if key in enabled_inputs_clipper:
#                 inputs += l
#     #clam
#     if config['run_clam']:
#         enabled_inputs_clam = list(available_inputs_clam)
#         for key, l in available_inputs_clam.items():
#             if key in enabled_inputs_clam:
#                 inputs += l
#     #cfpeak
#     if config['run_cfpeak']:
#         enabled_inputs_cfpeak = list(available_inputs_cfpeak)
#         for key, l in available_inputs_cfpeak.items():
#             if key in enabled_inputs_cfpeak:
#                 inputs += l
                
#     return inputs


rule all:
    input:
        get_all_inputs


#/BioII/lulab_b/jinyunfan/anaconda3/envs/bioinfo_py36/bin/bowtie2 (version 2.3.5)
rule transcript_index:
    input:
        genome_dir+'/fasta_newTxID/{rna_type}.fa'
    output:
        bt2_1=genome_dir+'/index/bowtie2/{rna_type}.1.bt2',
        bt2rev_1=genome_dir+'/index/bowtie2/{rna_type}.rev.1.bt2'
    params:
        output_prefix=genome_dir+'/index/bowtie2/{rna_type}'
    threads:
        config['threads_mapping']
    shell:
        '''bowtie2-build --threads {threads} {input} {params.output_prefix}
        '''


rule bam2fq1:
    input:
        
    threads:
        config['threads_mapping']
    params:
        inbam = "/lulab/baopengfei/shared_data/ENCODE/smallRNA-seq/fastq/{sample_id}/released/GRCh38/alignments/bam/rep*/*.bam", # ENCODE small/miRNA
        # inbam = "/data2/BioMedOmicsData/TCGA/processed/Bam/miRNA-Seq/*/*/{sample_id}.bam", # data2
        # inbam = "/lulab/baopengfei/shared_data/pub_tissueRNA/TCGA_small/*/*/{sample_id}.bam", # lulabdata
        # inbam = "/lulab/baopengfei/shared_data/pub_tissueRNA/TCGA-HNSC_small/HNSC/*/{sample_id}.bam", # lulabdata
        # inbam = "/Share2/home/lulab1/TCGA/processed/Bam/miRNA-Seq/*/*/{sample_id}.bam",
        # inbai = "/Share2/home/lulab1/TCGA/processed/Bam/miRNA-Seq/*/*/{sample_id}.bai",
        bam = temp_dir+"/{sample_id}.bam",
        # bai = temp_dir+"/{sample_id}.bai"
    output:
        fq = output_dir+"/trimmed/{sample_id}.fastq.gz",
    log:
        output_dir+'/trimmed/log/{sample_id}.log'
    shell:
        """
        samtools view -b -F 256 -F 4 {params.inbam} > {params.bam}
        samtools fastq -@ {threads} {params.bam} | gzip -c > {output.fq}
        """
#ln -f -s {params.inbam} {params.bam};ln -f -s {params.inbai} {params.bai}
#rm unmap or secondary alignments

#sample reads into similar scale, sequentially map to + strand of tx (by JYF)
rule mapping_tx:
    input:
        # fastq = "output/{dataset}/trimmed/{sample_id}.fastq.gz"
        fastq = output_dir+"/trimmed/{sample_id}.fastq.gz",
        idx1 = [ genome_dir+"/index/bowtie2/" + rna_type + ".1.bt2" for rna_type in rna_types ],
        idx2 = [ genome_dir+"/index/bowtie2/" + rna_type + ".rev.1.bt2" for rna_type in rna_types ],
    output:
        [ output_dir+"/tbam/{sample_id}/bam/" + rna_type + ".bam" for rna_type in rna_types ],
        [ output_dir+"/tbam/{sample_id}/bam/" + rna_type + ".bam.bai" for rna_type in rna_types ],
        [ temp(output_dir+"/tbam/{sample_id}/unmapped/" + rna_type + ".fastq.gz") for rna_type in rna_types1 ],
        # output_dir+"/tbam/{sample_id}/unmapped/enhancer_rev.fastq.gz",
        output_dir+"/tbam/{sample_id}/unmapped/repeats_rev.fastq.gz",
    log:
        output_dir+'/tbam/{sample_id}/log/rule'
    threads: config['threads_mapping']
    params:
        tmpdir = temp_dir,
        seed = config['seed'],
        downsample_fq = config['downsample_fq'],
        min_fq_num = config['min_fq_num'],
        max_fq_num = config['max_fq_num'],
        tmp_fq = output_dir+"/tbam/{sample_id}/tmp.fastq.gz",        
    wildcard_constraints:
        rna_type='(?!merge).*'
        # sample_id='\w+'
    shell:
        """
        (declare -i downsample_fq={params.downsample_fq}
        declare -i min_fq_num={params.min_fq_num}
        declare -i max_fq_num={params.max_fq_num}
        declare -i num=$((`seqkit stats --basename --tabular -j {threads} {input.fastq} | grep -v "file" | cut -f 4`))
        declare -i sub_num=$(($num*$downsample_fq/100))
        [ $num -lt $min_fq_num ] && sub_num=$(($num))
        [ $num -gt $min_fq_num -a $sub_num -lt $min_fq_num ] && sub_num=$(($min_fq_num))
        [ $sub_num -gt $max_fq_num ] && sub_num=$(($max_fq_num))

        if [ $sub_num -eq 0 ]; then echo "zero num of fq"; exit 1; fi

        echo "use fq num: $sub_num"

        seqtk sample -s {params.seed} \
            {input.fastq} $sub_num | pigz -c -p {threads} > {params.tmp_fq}

        export JOBLIB_TEMP_FOLDER={params.tmpdir}
        scripts/mapping.py \
            --fastq {params.tmp_fq} \
            --index-dir {genome_dir}/index/bowtie2 \
            --bam-dir {output_dir}/tbam/{wildcards.sample_id}/bam \
            --threads {threads} \
            --priority {priority} \
            --log-dir {output_dir}/tbam/{wildcards.sample_id}/log \
            --unmapped-dir {output_dir}/tbam/{wildcards.sample_id}/unmapped \
            --mode very-fast \
            --clip-mode end-to-end \
            --multimap-max 100 \
            )> {log} 2>&1
        rm {params.tmp_fq}
        """