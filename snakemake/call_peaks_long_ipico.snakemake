shell.prefix('set -x;')
# include: 'common.snakemake'
include: 'peak_common.snakemake'


# def get_all_inputs(wildcards):
#     available_inputs = dict(
#         ## star index
#         # Genome=expand(genome_dir+'/index/star/{rna_type}/Genome', rna_type=rna_types),
#         # SA=expand(genome_dir+'/index/star/{rna_type}/SA', rna_type=rna_types),

#         # ## bowtie2 index
#         # bt2_1=expand(genome_dir+'/index/bowtie2/{rna_type}.1.bt2', rna_type=rna_types),
#         # bt2rev_1=expand(genome_dir+'/index/bowtie2/{rna_type}.rev.1.bt2', rna_type=rna_types),

#         # bam=expand(output_dir+"/tbam/{sample_id}/bam/{rna_type}.bam",
#         #     sample_id=sample_ids, rna_type=rna_types),
#         # bam_dedup=expand("{output_dir}/tbam/{sample_id}/{bam_dedup_dir}/{rna_type}.bam",
#         #     output_dir=output_dir, sample_id=sample_ids, bam_dedup_dir=bam_dedup_dir, rna_type=rna_types),
#         # bam_dedup_merge_bam=expand("{output_dir}/tbam/{sample_id}/{bam_dedup_dir}/{rna_type}.bam",
#         #     output_dir=output_dir, sample_id=sample_ids, bam_dedup_dir=bam_dedup_dir, rna_type=['merge19_sort','merge11RNA_sort']), # merge11RNA_sort_primary
#         # realigned_reverted_bam=expand("{output_dir}/tbam/{sample_id}/{bam_dedup_dir}-EM/{rna_type}/merged.sorted.bam",
#         #     output_dir=output_dir, sample_id=sample_ids, bam_dedup_dir=bam_dedup_dir, rna_type=['merge19_sort']), #  'merge11RNA_sort',
#         # realigned_reverted_bam2=expand("{output_dir}/tbam/{sample_id}/{bam_dedup_dir}-EM/{rna_type}/{bam_type}",
#         #     output_dir=output_dir, sample_id=sample_ids, bam_dedup_dir=bam_dedup_dir, rna_type=['merge11RNA_sort'],bam_type=['unique.sorted.bam','unique.sorted.revertFullLengthReads.sorted.bam','allrealigned.sorted.bam'] ),

#         # bam_dedup2=expand("{output_dir}/tbam/{sample_id}/{bam_dedup_dir}/{rna_type}.bam",
#         #     output_dir=output_dir, sample_id=sample_ids, bam_dedup_dir=bam_dedup_dir, rna_type=['repeats_for','repeats_rev']),

#         # #bw
#         # tbw_EM= expand(peak_dir+'/tbigwig_RNA_EM/{sample_id}.transcriptome.bigWig',sample_id=sample_ids),
#         tbw_primary=expand(peak_dir+'/tbigwig_11RNA_primary/{sample_id}.transcriptome.bigWig',sample_id=sample_ids),


#         # ## merge_reads_by_rnatype=expand(peak_dir+'/tbed_long_RNA/{sample_id}.bed.gz',
#         # ##     sample_id=sample_ids),
#         bed=expand(peak_dir+'/tbed_11RNA_primary/{sample_id}.bed.gz',peak_dir=peak_dir,sample_id=sample_ids),
#         # ## bg=expand(peak_dir+'/tbedgraph_long_RNA/{sample_id}.transcriptome.bedGraph',peak_dir=peak_dir,sample_id=sample_ids),
#     )
#     available_inputs_piranha = dict(
#         # piranha
#         piranha_out=expand(peak_dir+'/piranha_by_sample/b{bin_size}_p{pvalue}/{sample_id}.bed',bin_size=config['bin_size'], pvalue=config['call_peak_pvalue_piranha'], sample_id=sample_ids),
#         peak_piranha=expand(peak_dir+'/piranha/b{bin_size}_p{pvalue}.bed',bin_size=config['bin_size'], pvalue=config['call_peak_pvalue_piranha']),
#         peak_count_matrix_piranha=expand(peak_dir+'/count_matrix/piranha_b{bin_size}_p{pvalue}.txt',bin_size=config['bin_size'], pvalue=config['call_peak_pvalue_piranha'])
#     )
#     available_inputs_clipper = dict(
#         # clipper
#         clipper_out=expand(peak_dir+'/clipper_by_sample/b{bin_size}_p{pvalue}/{sample_id}.bed',bin_size=config['bin_size'], pvalue=config['call_peak_pvalue_clipper'], sample_id=sample_ids),
#         peak_clipper=expand(peak_dir+'/clipper/b{bin_size}_p{pvalue}.bed',bin_size=config['bin_size'], pvalue=config['call_peak_pvalue_clipper']),
#         peak_count_matrix_clipper=expand(peak_dir+'/count_matrix/clipper_b{bin_size}_p{pvalue}.txt',bin_size=config['bin_size'], pvalue=config['call_peak_pvalue_clipper'])
#     )
#     available_inputs_clam = dict(
#         # clam
#         clam_out=expand(peak_dir+'/clam_by_sample/b{bin_size}_p{pvalue}/{sample_id}.bed',bin_size=config['bin_size'], pvalue=config['call_peak_pvalue_clam'], sample_id=sample_ids),
#         peak_clam=expand(peak_dir+'/clam/b{bin_size}_p{pvalue}.bed',bin_size=config['bin_size'], pvalue=config['call_peak_pvalue_clam']),
#         peak_count_matrix_clam=expand(peak_dir+'/count_matrix/clam_b{bin_size}_p{pvalue}.txt',bin_size=config['bin_size'], pvalue=config['call_peak_pvalue_clam'])
#     )
#     available_inputs_cfpeak = dict(
#         # # localmax
#         # localmax_out=expand(peak_dir+'/peaks_localmax_by_sample/b{bin_size}_d{decay}_p{pvalue}/{sample_id}.bed',bin_size=config['bin_size'], decay=config['decay_ratio'], pvalue=config['call_peak_pvalue'], sample_id=sample_ids),
#         # peaks_localmax=expand(peak_dir+'/peaks_localmax/b{bin_size}_d{decay}_p{pvalue}.bed', bin_size=config['bin_size'], decay=config['decay_ratio'], pvalue=config['call_peak_pvalue']),
#         # peak_count_matrix=expand(peak_dir+'/count_matrix/peaks_long_localmax_b{bin_size}_d{decay}_p{pvalue}.txt',peak_dir=peak_dir, bin_size=config['bin_size'], decay=config['decay_ratio'], pvalue=config['call_peak_pvalue']),

#         # ## cfPeak
#         # localmax_out3=expand(peak_dir+'/cfpeak_by_sample/b{bin_size}_d{decay}_p{pvalue}/{sample_id}.bed',bin_size=config['bin_size'],decay=config['decay_ratio'], pvalue=config['call_peak_pvalue_cfpeak'], sample_id=sample_ids),
#         # peak_localmax3=expand(peak_dir+'/cfpeak/b{bin_size}_d{decay}_p{pvalue}.bed', bin_size=config['bin_size'], decay=config['decay_ratio'], pvalue=config['call_peak_pvalue_cfpeak']),
#         # peak_count_matrix3=expand(peak_dir+'/count_matrix/cfpeak_b{bin_size}_d{decay}_p{pvalue}.txt',peak_dir=peak_dir, bin_size=config['bin_size'], decay=config['decay_ratio'], pvalue=config['call_peak_pvalue_cfpeak']),

#         ## cfPeakCNN
#         localmax_out4=expand(peak_dir+'/cfpeakCNN_by_sample/b{bin_size}_d{decay}_p{pvalue}/{sample_id}.bed',bin_size=config['bin_size'],decay=config['decay_ratio'], pvalue=config['call_peak_pvalue_cfpeak'], sample_id=sample_ids),
#         peak_localmax4=expand(peak_dir+'/cfpeakCNN/b{bin_size}_d{decay}_p{pvalue}.bed', bin_size=config['bin_size'], decay=config['decay_ratio'], pvalue=config['call_peak_pvalue_cfpeak']),
#         peak_count_matrix4=expand(peak_dir+'/count_matrix/cfpeakCNN_b{bin_size}_d{decay}_p{pvalue}.txt',peak_dir=peak_dir, bin_size=config['bin_size'], decay=config['decay_ratio'], pvalue=config['call_peak_pvalue_cfpeak'])
#     )

#     inputs = []

#     enabled_inputs = list(available_inputs)
#     for key, l in available_inputs.items():
#         if key in enabled_inputs:
#             inputs += l
    
#     #piranha
#     if config['run_piranha']:
#         enabled_inputs_piranha = list(available_inputs_piranha)
#         for key, l in available_inputs_piranha.items():
#             if key in enabled_inputs_piranha:
#                 inputs += l
#     #clipper
#     if config['run_clipper']:
#         enabled_inputs_clipper = list(available_inputs_clipper)
#         for key, l in available_inputs_clipper.items():
#             if key in enabled_inputs_clipper:
#                 inputs += l
#     #clam
#     if config['run_clam']:
#         enabled_inputs_clam = list(available_inputs_clam)
#         for key, l in available_inputs_clam.items():
#             if key in enabled_inputs_clam:
#                 inputs += l
#     #cfpeak
#     if config['run_cfpeak']:
#         enabled_inputs_cfpeak = list(available_inputs_cfpeak)
#         for key, l in available_inputs_cfpeak.items():
#             if key in enabled_inputs_cfpeak:
#                 inputs += l
                
#     return inputs

rule all:
    input:
        get_all_inputs

# option1: sequential map to tx by bowtie2 (JYF script). for reverse strand PE consider only using read2
#--sentive mode deprecated, too slow
#keep in mind to handle multi-mapped reads in repeats regions, see "Handling multi-mapped reads in RNA-seq"
#for bowtie2 default, will find multiple alignments, but only report best one with MAPQ, other secondary alignment MAPQ is < 40. 
#secondary alignment not using sam/bam flag 
#https://sequencing.qcfail.com/articles/mapq-values-are-really-useful-but-their-implementation-is-a-mess/

rule transcript_index_long:
    input:
        genome_dir+'/fasta_newTxID/{rna_type}.fa'
    output:
        bt2_1=genome_dir+'/index/bowtie2/{rna_type}.1.bt2',
        bt2rev_1=genome_dir+'/index/bowtie2/{rna_type}.rev.1.bt2'
    params:
        output_prefix=genome_dir+'/index/bowtie2/{rna_type}'
    threads:
        config['threads_mapping']
    shell:
        '''/BioII/lulab_b/jinyunfan/anaconda3/envs/bioinfo_py36/bin/bowtie2-build --threads {threads} {input} {params.output_prefix}
        '''

# sequential map to tx (JYF script), only map tx for +
rule mapping_tx_long:
    input:
        # fastq = "output/{dataset}/trimmed/{sample_id}.fastq.gz"
        fastq1 = output_dir+"/trimGC/{sample_id}_1.fastq.gz" if (config['strandness']=="forward") else output_dir+"/trimGC/{sample_id}_2.fastq.gz",
        fastq2 = output_dir+"/trimGC/{sample_id}_2.fastq.gz" if (config['strandness']=="forward") else output_dir+"/trimGC/{sample_id}_1.fastq.gz",
        idx1 = [ genome_dir+"/index/bowtie2/" + rna_type + ".1.bt2" for rna_type in rna_types ],
        idx2 = [ genome_dir+"/index/bowtie2/" + rna_type + ".rev.1.bt2" for rna_type in rna_types ],
    output:
        [ output_dir+"/tbam/{sample_id}/bam/" + rna_type + ".bam" for rna_type in rna_types ],
        [ output_dir+"/tbam/{sample_id}/bam/" + rna_type + ".bam.bai" for rna_type in rna_types ],
        [ temp(output_dir+"/tbam/{sample_id}/unmapped/" + rna_type + ".fastq.gz") for rna_type in rna_types1 ],
        # output_dir+"/tbam/{sample_id}/unmapped/enhancer_rev.fastq.gz",
        output_dir+"/tbam/{sample_id}/unmapped/repeats_rev.fastq.gz",
    log:
        output_dir+'/tbam/{sample_id}/log/rule'
    threads: config['threads_mapping']
    params:
        tmpdir = temp_dir,
        fastp_fq = output_dir+"/tbam/{sample_id}/fastp.fastq.gz",
        seed = config['seed'],
        downsample_fq = config['downsample_fq'],
        downsample_fq_ratio = str(config['seed'])+"."+str(config['downsample_fq']),
        min_fq_num = config['min_fq_num'],
        max_fq_num = config['max_fq_num'],
        tmp_fq = output_dir+"/tbam/{sample_id}/tmp.fastq.gz",        
    wildcard_constraints:
        rna_type='(?!merge).*'
        # sample_id='\w+'
    shell:
        """
        (fastp -w {threads} -i {input.fastq1} -I {input.fastq2} --merge --merged_out {params.fastp_fq}
            
        declare -i downsample_fq={params.downsample_fq}
        declare -i min_fq_num={params.min_fq_num}
        declare -i num=$((`seqkit stats --basename --tabular -j {threads} {params.fastp_fq} | grep -v "file" | cut -f 4`))
        declare -i sub_num=$(($num*$downsample_fq/100))
        [ $num -lt $min_fq_num ] && sub_num=$(($num))
        [ $num -gt $min_fq_num -a $sub_num -lt $min_fq_num ] && sub_num=$(($min_fq_num))
        [ $sub_num -gt $max_fq_num ] && sub_num=$(($max_fq_num))
        echo "use fq num: $sub_num"

        seqtk sample -s {params.seed} \
            {params.fastp_fq} $sub_num | pigz -c -p {threads} > {params.tmp_fq}

        export JOBLIB_TEMP_FOLDER={params.tmpdir}
        scripts/mapping.py \
            --fastq {params.tmp_fq} \
            --index-dir {genome_dir}/index/bowtie2 \
            --bam-dir {output_dir}/tbam/{wildcards.sample_id}/bam \
            --threads {threads} \
            --priority {priority} \
            --log-dir {output_dir}/tbam/{wildcards.sample_id}/log \
            --unmapped-dir {output_dir}/tbam/{wildcards.sample_id}/unmapped \
            --mode very-fast \
            --clip-mode end-to-end \
            --multimap-max 100 \
            )> {log} 2>&1
        rm {params.tmp_fq} {params.fastp_fq}
        """
